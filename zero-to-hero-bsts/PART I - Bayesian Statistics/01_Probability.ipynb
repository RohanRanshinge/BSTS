{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 1: Probability\n",
        "We can’t do Bayesian Statistics without learning about probability first! Personally, I never found probability fun. I always struggled with those questions of finding the probability of landing 5 heads consecutively or the probability of picking one ace and two queens from three decks of cards etc. I know some of you may be thinking “oh, that’s so obvious, what’s so hard about probability”. If you are already familiar with probability and are comfortable with it feel free to skip this section, but for those of us that find it challenging, this might be worth a read. (I haven’t gone into great detail here though as the intention is to just introduce the concept).\n",
        "## Super Basics\n",
        "Starting from scratch, let’s first define probability: \\\n",
        "Probability is the chance of observing a certain event.\n",
        "\n",
        "For example, when we toss a coin, how likely is it to come up a head or a tail?\n",
        "> ½\n",
        "\n",
        "Or what is the probability of rolling a 3 on a fair six-sided die?\n",
        "> ⅙\n",
        "\n",
        "Notation: P(X=3) = ⅙\n",
        "\n",
        "\n",
        "An important characteristic of probability is that the probabilities of all events should always add to one. \\\n",
        "* That is, if the probability of X being 3 is 1/6 , then the probability of X not being 3 is ⅚ \\\n",
        "    * if P(X=3) = ⅙, then P(X!=3) = ⅚ \\\n",
        "* Sum(both events) = 1\n",
        "\n",
        "\\\n",
        "Probabilities are a way of assigning numbers to a set of mutually exclusive possibilities.\n",
        "\n",
        "Let’s look at two key terms that will come in handy in the future:\n",
        "## Odds\n",
        "Probabilities can also be expressed in terms of odds. You’ve likely encountered odds before. When folks say “*we have overcome great odds to be here*” they basically are talking about probability where chances of success were very slim. Some of you may recall, Leicester City won the Premier League in 2015 with 5000-1 odds. (Those odds look almost impossible but in the world of football anything is possible).\n",
        "\n",
        "So what does this mean exactly?\\\n",
        "In our previous example of rolling a 3 on a fair six sided die, P(A) = ⅙ \\\n",
        "The odds for event A is then given as\n",
        "\n",
        "$O(A) = \\frac{P(A)}{P(A^c)} = \\frac{P(A)}{1-P(A)}$ \\\n",
        "\n",
        "$O(A) = \\frac{1/6}{5/6}= \\frac{1}{5} $\n",
        "\n",
        "This can also be written as 1:5 (or 5:1 odds against). \\\n",
        "So if an event has a ⅙ probability of happening its odds are 1:5\n",
        "\n",
        "\n",
        "Let’s look at another example? \\\n",
        "Imagine the probability of seeing a shooting star is 3/100 \\\n",
        "Therefore, its odds are $O(A) = \\frac{3/100}{97/100}= \\frac{3}{97}=3:97$\n",
        "\n",
        "Or the odds against seeing a shooting star are 97:3\n",
        "\n",
        "Similarly, an event with higher probability of ⅔ has 2:1 odds.\n",
        "\n",
        "Using this information, we can also back calculate probabilities from odds. \\\n",
        "ie. X:Y odds can be rewritten as $\\frac{X}{X+Y}$\n",
        "\n",
        "\n",
        "In simpler terms, an event with 3:7 odds has a probability of $\\frac{3}{10}$\n",
        "\n",
        "Looking at our previous example of Leicester city winning the Premier League. \\\n",
        "They had a 5000-1 odds against winning, which means odds of winning were 1:5000 \\\n",
        "$P(winning) = \\frac{X}{X+Y} = \\frac{1}{5000+1}$ \\\n",
        "\n",
        "$ P(winning) = \\frac{1}{5001}$\n",
        "\n",
        "## Expected value\n",
        "In simple terms, the expected value is the **average** of the variable.\n",
        "\n",
        "In slightly more technical terms, the expected value of a random variable X is the weighted average of values X, where the weights are the probabilities of those values.\n",
        "\n",
        "\n",
        "It's adding up each possible value, but each value is multiplied by its chance of happening first.\n",
        "\n",
        "Taking the example of a fair sided die the expected value is \\\n",
        "$ E(X) = \\frac{1}{6}*(1+2+3+4+5+6) = 3.5$ \\\n",
        "Since each side is equally likely we sum up all the values and divide them by 6.\n",
        "\n",
        "## Frameworks for Defining Probabilities\n",
        "There are three main frameworks we need to be aware of for defining probabilities\n",
        "1. Classical framework\\\n",
        "  a. Outcomes that are equally likely have equal probabilities. (rolling a fair die)\n",
        "2. Frequentist framework\\\n",
        "  a. You have a hypothetical infinite sequence and then look at the frequency of outcomes in that hypothetical infinite sequence (if a die is rolled infinitely, probability of rolling a 2 is 1 in 6)\n",
        "3. Bayesian framework\\\n",
        "  a. Based on personal perspective. Takes into account what you know about a particular problem\\\n",
        "\n",
        "We will be using the Bayesian framework here.\n",
        "## Recommended Readings\n",
        "Bayesian Statistics: From Concept to Data Analysis ([Coursera](https://www.coursera.org/learn/bayesian-statistics/home/module/1))\n"
      ],
      "metadata": {
        "id": "QyLh4iK6TO3e"
      }
    }
  ]
}
